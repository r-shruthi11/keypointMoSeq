import os
"""
This script receives as input a project_dir that contains a specific config.yml file.
It initializes a model with the parameters specified in the config.yml file.
It fits the model with data from sleap experiments that are read and initialized as
per usual while fitting any model with experiments.
In the case of the hyperparameter sweep, the experiments are split in train-test splits.
For now, there are 5 experiments that I am fitting the models on.
I will take four of these experiments to train the model on and evaluate the model on the
fifth experiment.

The script is launched on Della using a SLURM array job that iterates over the array_args.txt
file that is generated by generate_hyperparams_configs.py. The array_args.txt file contains
a list of project_dirs.
"""

import numpy as np
from keypoint_moseq.project.fit_utils import find_sleap_paths, load_data_from_expts, run_fit_PCA, fit_keypoint_ARHMM, \
    resume_slds_fitting_to_new_data, fit_mvn, print_ll, calculate_test_bits, calculate_train_bits
from keypoint_moseq.run.hyperparams.get_test_probs import get_test_probs
from keypoint_moseq.project.io import save_llh, load_llh

import argparse
from rich.pretty import pprint
from sklearn.model_selection import KFold


def create_cli_parser():
    """Create an argument parser for the command line interface."""
    parser = argparse.ArgumentParser(
        description="Sweep hyperparameters for ARHMM and SLDS models on SLEAP data."
    )
    parser.add_argument(
        "-p",
        "--project_dir",
        type=str,
        required=True,
        help="Path to project directory containing config.yml file.",
    )
    parser.add_argument(
        "-v",
        "--video_dir",
        type=str,
        required=True,
        help="Path to video directory containing sleap experiments.",
    )
    parser.add_argument('--use_instance', type=int, default=1)

    return parser


def sample_paths_for_initialization(sleap_paths):
    # TODO (US): sample randomly
    init_paths = sleap_paths[:5]
    return init_paths


def train(train_paths, project_dir, use_instance):

    init_paths = sample_paths_for_initialization(train_paths)

    # Load train data from train experiment folders
    data, batch_info = load_data_from_expts(init_paths, project_dir, use_instance)

    # Fit PCA
    run_fit_PCA(data, project_dir)

    # Initialize and fit ARHMM
    _, _, name = fit_keypoint_ARHMM(project_dir, data, batch_info)

    # Fit SLDS
    checkpoint_path = os.path.join(project_dir, name, 'checkpoint.p')
    name, llh = resume_slds_fitting_to_new_data(checkpoint_path, project_dir, train_paths)

    return name, llh


def fitCV(sleap_paths, project_dir, use_instance):
    """

    Parameters
    ----------
    sleap_paths
    project_dir

    Returns
    -------

    """
    sleap_paths = np.array(sleap_paths)

    llh = {
        'train': {'log_Y_and_model': [], 'log_Y_given_model': [], 'log_Y_given_mvn': [], 'n_samples': []},
        'test': {'log_Y_and_model': [], 'log_Y_given_model': [], 'log_Y_given_mvn': [], 'n_samples': []},
    }

    if len(sleap_paths) <= 1:
        model_name, train_llh = train(sleap_paths, project_dir, use_instance)
        print("model_name", model_name)
        llh['train']['log_Y_and_model'].append(train_llh['log_Y_and_model'])
        llh['train']['log_Y_given_model'].append(train_llh['log_Y_given_model'])
        return llh

    kfold = KFold(n_splits=np.min([5, len(sleap_paths)]))
    for tr, te in kfold.split(sleap_paths):
        print(">>> tr", tr, "te", te)
        train_paths, test_paths = sleap_paths[tr], sleap_paths[te]

        model_name, train_llh = train(train_paths, project_dir, use_instance)
        train_log_Y_given_mvn, n_samples = fit_mvn(train_paths, project_dir, use_instance)
        print("model_name:", model_name)
        print(train_llh)
        llh['train']['log_Y_and_model'].append(train_llh['log_Y_and_model'])
        llh['train']['log_Y_given_model'].append(train_llh['log_Y_given_model'])
        llh['train']['log_Y_given_mvn'].append(train_log_Y_given_mvn)
        llh['train']['n_samples'].append(n_samples)

        test_log_y_and_model, test_log_ll = get_test_probs(test_paths, project_dir, model_name, use_instance)
        test_log_Y_given_mvn, n_samples = fit_mvn(test_paths, project_dir, use_instance)
        llh['test']['log_Y_and_model'].append([test_log_y_and_model])
        llh['test']['log_Y_given_model'].append([test_log_ll])
        llh['test']['log_Y_given_mvn'].append(test_log_Y_given_mvn)
        llh['test']['n_samples'].append(n_samples)

        print(f"Test LLs for split: (tr={tr}, te={te}): "
              f"\tlog(y,model)=", test_log_y_and_model, "\tlog(y|model)=", test_log_ll)

    print("llh", llh)
    save_llh(llh, project_dir)
    return


def main():
    # Main control flow of the experiment
    # Parse CL args
    parser = create_cli_parser()
    args = parser.parse_args()
    print("Args:")
    pprint(vars(args))
    print()
    video_dir = args.video_dir
    project_dir = args.project_dir
    use_instance = args.use_instance

    # Get sleap experiment folders 
    sleap_paths = find_sleap_paths(video_dir)
    print("sleap_paths", sleap_paths)
    sleap_paths = np.array(sleap_paths)

    # Do cross validation
    fitCV(sleap_paths, project_dir, use_instance)

    # Plot training and test loglikelihoods
    llh = load_llh(project_dir)
    print_ll(llh)
    calculate_train_bits(llh['train'])
    calculate_test_bits(llh['test'])
    return


if __name__ == "__main__":
    main()
